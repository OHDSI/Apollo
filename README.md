Assessment of Pre-trained Observational Large Longitudinal models in OHDSI (APOLLO)
===================================================================================

[![Build Status](https://github.com/OHDSI/Apollo/workflows/Build-and-test/badge.svg)](https://github.com/OHDSI/Apollo/actions?query=workflow%3ABuild-and-test)

## Introduction
This Python package is for building and evaluating large general pre-trained models on data in the OMOP Common Data Model (CDM) format. The models are fitted on the structured data (concepts) in the CDM, not any natural language. We aim to evaluate these models on various tasks, such as patient-level prediction (either zero-shot or fine-tuned).

# Overview
This package assumes the [GeneralPretrainedModelTools](https://github.com/OHDSI/GeneralPretrainedModelTools) R package has been executed to retrieve (a sample of) the CDM data to local Parquet files. After this, a 'cdm_processor' must be run to convert the data to sequence data suitable for a large language model. TODO: how to go from here. 

## Getting Started

### Pre-requisite
The project is built in python 3.10, and project dependency needs to be installed 

Create a new Python virtual environment
```console
python -m venv venv;
source venv/bin/activate;
```

Install the packages in requirements.txt
```console
pip install -r requirements.txt
```

### Simulate CDM data

In real-world applications, the CDM data can be retrieved from a database using the [GeneralPretrainedModelTools R package](https://github.com/OHDSI/GeneralPretrainedModelTools). 
For testing purposes, we can simulate CDM data using a built-in simulator:

1. Edit simulation.ini so the `root_folder` argument points to a folder on the local file system.

2. Run:

    ```python
	python simulation/simulation.py simulation.ini
	```
   
By default, the simulation script will generate pretraining data in a subfolder called 'pretraining'. 


In addition, data will be generated for a patient-level prediction task, where patient data up to an index date is used to predict whether a patient will have a certain condition in the prediction window (default = 365 days) after the index date.
Training data, for fine-tuning the pretrained model, will be generated in a subfolder called 'train'.
Test data, for evaluating the fine-tuned model, will be generated in a subfolder called 'test'. 
In both 'train' and 'test' folders, subfolders will be generated for each simulated concept ID with labels indicating whether the concept was observed in the prediction window.

### Procesing CDM data for CEHR-BERT pre-training

1. Edit cehr-bert.ini to point to folders on the local file system, e.g. the 'pretraining' folder generated by the simulation script.

2. Run:

    ```python
	python cdm_processing/cehr_bert_cdm_processor.py cehr_bert.ini
	```

## License

Apollo is licensed under Apache License 2.0.

## Development status

Under development. Do not use.
